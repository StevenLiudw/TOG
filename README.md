# Training-free Task-oriented Grasp Generation

This project integrates **Contact GraspNet** and **ManiSkill** to enable a robotic system to generate task-oriented grasps **without training**. The system consists of two main components:

1. **Contact GraspNet** - Generates grasp candidates based on object geometry.
2. **ManiSkill** - Controls the robotic arm to execute grasping actions based on task requirements.

---

## ğŸš€ Getting Started

### 1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/your_username/Training-free-Task-oriented-Grasp-Generation.git
cd Training-free-Task-oriented-Grasp-Generation
```

---

## ğŸ›  Setup Instructions

### Step 1: Setup Conda Environments
Ensure you have **Conda** installed. Then, activate the required environments:

#### Grasp Generation (Contact GraspNet)
```bash
conda activate cgn_env
```

#### Robot Control (ManiSkill)
```bash
conda activate mani_env2
```

---

### Step 2: Start the Contact GraspNet Server
In the **first terminal**, navigate to the Contact GraspNet directory and launch the **grasping server**:

```bash
cd ./third_party/contact_graspnet/contact_graspnet/
python socket_server.py
```
ğŸ”¹ This starts a socket server that generates task-oriented grasping points.

---

### Step 3: Run the Robot Controller
In **another terminal**, activate the **ManiSkill** environment and execute the robot control script:

```bash
conda activate mani_env2
python move_robot.py --task task_1 --model gemini --task_idx 1 --visual_method gripper_one
```

#### Command Arguments:
| Argument | Description |
|----------|------------|
| `--task task_1` | Specifies the task (e.g., gripping toys). |
| `--model gemini` | Model used for grasp evaluation. |
| `--task_idx 1` | Index of the task instance. |
| `--visual_method gripper_one` | Defines the visualization method for grasp execution. |

---

## ğŸ“¦ Project Structure
```
Training-free-Task-oriented-Grasp-Generation/
â”‚â”€â”€ third_party/
â”‚   â”œâ”€â”€ contact_graspnet/  # Contact GraspNet source
â”‚   â”œâ”€â”€ mani_skill/        # ManiSkill environment
â”‚â”€â”€ move_robot.py          # Robot movement script
â”‚â”€â”€ README.md              # Project documentation
â”‚â”€â”€ requirements.txt       # Dependencies
â”‚â”€â”€ LICENSE                # License file
```

---

## ğŸ”§ Dependencies
Make sure the following dependencies are installed in their respective environments:

### cgn_env (for grasp generation)
```bash
pip install torch numpy open3d transforms3d scipy
```

### mani_env2 (for robot control)
```bash
pip install mani_skill2 gym numpy scipy
```

Alternatively, install all dependencies from `requirements.txt`:
```bash
pip install -r requirements.txt
```

---

## ğŸ›  Troubleshooting
### âŒ Issue: Contact GraspNet Server Not Responding
âœ” Ensure `cgn_env` is activated before running `socket_server.py`.

### âŒ Issue: Robot Not Moving
âœ” Check if `mani_env2` is activated before running `move_robot.py`.

### âŒ Issue: Environment Not Found
âœ” Verify that `cgn_env` and `mani_env2` are installed with the correct dependencies.

---

## ğŸ‘¨â€ğŸ’» Contributors
- **Your Name** (Modify as needed)

---

## ğŸ“œ License
This project is licensed under the **MIT License**. See the [`LICENSE`](LICENSE) file for details.

---

## ğŸ¤ Acknowledgements
- **Contact GraspNet** ([GitHub Repo](https://github.com/NVlabs/ContactGraspNet))
- **ManiSkill** ([GitHub Repo](https://github.com/haosulab/ManiSkill2))

---

## âœ¨ Future Work
- ğŸ›  Improve grasp selection with heuristic-based refinement.
- ğŸ”„ Extend to multi-object grasping scenarios.
- ğŸ§  Explore reinforcement learning for fine-tuned grasp execution.
